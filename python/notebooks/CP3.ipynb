{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.datasets import load_iris\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.datasets import load_breast_cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "# Target Transformation (Log Transformation)\n",
    "# Load the california housing data set and apply a log transformation to\n",
    "# the target variable (MedHouseVal) to make its distribution closer to normal\n",
    "\n",
    "housing_data = fetch_california_housing()\n",
    "y = housing_data.target\n",
    "\n",
    "plt.hist(y, bins=50)\n",
    "plt.xlabel(\"MedHouseVal\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Original Distribution of MedHouseVal\")\n",
    "plt.show()\n",
    "\n",
    "y_log = np.log1p(y) # log transfromation\n",
    "plt.hist(y_log, bins=50)\n",
    "plt.xlabel(\"log MedHouseVal\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Log-Transformed Distribution of MedHouseVal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 \n",
    "# Categorical Feature Encoding (One-Hot Encoding)\n",
    "# Perform one-hot encoding on the Embarked feature using pandas.get_dummies()\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df['embarked'].head())\n",
    "df_encoded = pd.get_dummies(df, columns=['embarked'])\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "# Handling Missing Values (Imputation)\n",
    "# Apply imputation for missing numerical values using the median on the iris dataset\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "np.random.seed(42)\n",
    "missing_indices = np.random.choice(df.index, size=10, replace=False) # randomly assign missing values\n",
    "df.loc[missing_indices, 'sepal length (cm)'] = np.nan\n",
    "\n",
    "print(\"Amount of missing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[[\"sepal length (cm)\"]] = imputer.fit_transform(df[[\"sepal length (cm)\"]])\n",
    "\n",
    "print(\"Amount of missing values after imputation:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "# Outlier Detection (Z-Score)\n",
    "# Detect and remove outliers from the California housing dataset using the Z-score method\n",
    "\n",
    "housing_data = fetch_california_housing()\n",
    "df = pd.DataFrame(housing_data.data, columns=housing_data.feature_names)\n",
    "print('Shape before outlier removal:', df.shape)\n",
    "\n",
    "z_scores = np.abs(zscore(df))\n",
    "no_outliers_df = df[(z_scores <= 3).all(axis=1)]\n",
    "print(\"Shape after outlier removal:\", no_outliers_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 \n",
    "# Feature Scaling (Standardization vs Normailization)\n",
    "# Perform feature scaling on the wine quality dataset using both standardization and normalization\n",
    "\n",
    "wine_data = fetch_ucirepo(id=186)\n",
    "\n",
    "X = wine_data.data.features\n",
    "y = wine_data.data.targets\n",
    "print('Features:')\n",
    "print(X.head())\n",
    "print('Targets:')\n",
    "print(y.head())\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_standardized = standard_scaler.fit_transform(X)\n",
    "X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "print('Standardized Features:')\n",
    "print(X_standardized_df.head())\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_normalized = minmax_scaler.fit_transform(X)\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "print('Normalized Features:')\n",
    "print(X_normalized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6\n",
    "# Binning (Discretization)\n",
    "# Apply binning to the Age feature in the diabetes dataset\n",
    "\n",
    "df = pd.read_csv('../datasets/diabetes.csv')\n",
    "\n",
    "bins = [0, 30, 65, 100]\n",
    "labels = [\"Under 30\", \"Middle-aged\", \"Senior(65+)\"]\n",
    "df[\"Age_binned\"] = pd.cut(\n",
    "    df[\"Age\"],\n",
    "    bins=bins,\n",
    "    labels=labels\n",
    ")\n",
    "print(df[\"Age_binned\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7\n",
    "# Feature Extraction (Principal Component Analysis)\n",
    "# Perform feature extraction using Principal Component Analysis (PCA) on Breast Cancer Dataset\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "X = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "y = cancer_data.target\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) # PCA is scale-sensitive so standardization is required\n",
    "\n",
    "pca = PCA(n_components=2) # Reduce dataset to 2 dimensions\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y, cmap=\"coolwarm\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"PCA Breast Cancer Dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c26e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8\n",
    "# Feature Selection (Recursive Feature Elimination)\n",
    "# Use Recursive Feature Elimination (RFE) to select the most important (top 5) features for predicting wine quality.\n",
    "\n",
    "wine_data = fetch_ucirepo(id=186)\n",
    "\n",
    "X = wine_data.data.features\n",
    "y = wine_data.data.targets\n",
    "print('Original:')\n",
    "print(X.columns)\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "rfe.fit(X, y)\n",
    "print('Selected features:')\n",
    "print(X.columns[rfe.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9\n",
    "# Feature Engineering with Time Series Data\n",
    "# Create new features from the time series data to predict the air quality in a given city.\n",
    "\n",
    "air_quality = fetch_ucirepo(id=360) \n",
    "\n",
    "df = air_quality.data.features\n",
    "\n",
    "df[\"Datetime\"] = pd.to_datetime(\n",
    "    df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str),\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df[\"day_of_week\"] = df[\"Datetime\"].dt.dayofweek\n",
    "df[\"hour\"] = df[\"Datetime\"].dt.hour\n",
    "df[\"month\"] = df[\"Datetime\"].dt.month\n",
    "print(df[[\"Datetime\", \"day_of_week\", \"hour\", \"month\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ef9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10\n",
    "# Feature Transformation (Polynomial Features)\n",
    "# Use polynomial features to enhance a linear regression model for predicting house prices of California housing dataset.\n",
    "\n",
    "housing_data = fetch_california_housing()\n",
    "\n",
    "X = housing_data.data\n",
    "y = housing_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nPolynomial Regression (Degree 2)\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R Squared:\", r2)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "print(\"\\nPolynomial Regression (Degree 2)\")\n",
    "print(\"MSE:\", mse_poly)\n",
    "print(\"R Squared:\", r2_poly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
