{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 \n",
    "# Dataset Creation\n",
    "# Create a dataset containing three columns:\n",
    "# The first column should list five movies that you have watched.\n",
    "# The second column should describe some highlighted features of the movies \n",
    "# The third column should describe some drawbacks of the movies that you can think of.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Movie': ['Interstellar', 'Moneyball', 'Forrest Gump', 'The Big Short', 'Greenland'],\n",
    "    'Highlights': ['Really cool visuals!', 'Interesting story', 'Emotional plot', 'Highlights corruption in banks', 'Intense, action-filled escapes'],\n",
    "    'Drawbacks': ['Long and slow-moving.', 'Historically inaccurate', 'Toxic romance', 'Excessive narration, and 4th wall breaks', 'Some characters\\' choices are frustrating']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391bd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 \n",
    "# Data cleaning\n",
    "# Remove all punctuation marks from the \"Highlights\" and \"Drawbacks\" columns.\n",
    "\n",
    "import string \n",
    "import re\n",
    "\n",
    "regex_punctuation = f'[{re.escape(string.punctuation)}]'\n",
    "\n",
    "df['Highlights'] = df['Highlights'].str.replace(regex_punctuation, '', regex=True)\n",
    "df['Drawbacks'] = df['Drawbacks'].str.replace(regex_punctuation, '', regex=True)\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a40543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "# Unique Word Count\n",
    "# Add a new column to the dataset that contains the count of unique words from\n",
    "# both the \"Highlights\" and \"Drawbacks\" columns for each row (from question 2).\n",
    "\n",
    "def unique_word_count(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "df['Unique Word Count'] = df['Highlights'].apply(unique_word_count) + df['Drawbacks'].apply(unique_word_count)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "# Bar Chart\n",
    "# Create a bar chart (Bar Plot) that displays the total word count (combining the \n",
    "# word count from both the \"Highlights\" and \"Drawbacks\" columns - question 3) for \n",
    "# each movie in the dataset. The x-axis should represent the movie names, and \n",
    "# the y-axis should represent the word count.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(df['Movie'], df['Unique Word Count'])\n",
    "plt.xlabel('Movie')\n",
    "plt.ylabel('Unique Word Count in Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 \n",
    "# Import Dataset\n",
    "# Import the Iris dataset using the given link or from sklearn to your notebook.\n",
    "# Use a dataframe to store the iris data.\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "iris = fetch_ucirepo(id=53) \n",
    "iris_df = pd.DataFrame(iris.data.original)\n",
    "\n",
    "print(iris_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6\n",
    "# Scatterplot\n",
    "# Use a scatterplot to show all the classes of Iris dataset\n",
    "\n",
    "plt.scatter(iris_df['sepal length'], iris_df['sepal width'])\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(iris_df['petal length'], iris_df['petal width'])\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68907fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 \n",
    "# Data Exploration\n",
    "# Perform an exploration of the Iris dataset (from question 5) by calculating \n",
    "# summary statistics for each numeric feature. Use Pandas to compute \n",
    "# mean, median, standard deviation\n",
    "\n",
    "numeric_columns = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    mean = iris_df[col].mean()\n",
    "    median = iris_df[col].median()\n",
    "    std = iris_df[col].std()\n",
    "\n",
    "    print(col +':' \n",
    "          + '\\nMean: ' + str(mean)\n",
    "          + '\\nMedian: ' + str(median)\n",
    "          + '\\nStandard deviation: ' + str(std) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8\n",
    "# Feature Scaling\n",
    "# Apply feature scaling to standardize the Iris dataset's (from question 5) numeric \n",
    "# features using StandardScaler. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(iris.data.features)\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=iris.data.features.columns)\n",
    "print(scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b158726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9\n",
    "# Correlation Analysis\n",
    "# Find the correlation between sepal and petal length of Iris Dataset (from question 5). \n",
    "# Also find the correlation matrix of numeric features.\n",
    "\n",
    "sepal_petal_corr = iris_df['sepal length'].corr(iris_df['petal length'])\n",
    "print('Correlation between sepal length and petal length: ' + str(sepal_petal_corr))\n",
    "\n",
    "corr_matrix = iris.data.features.corr()\n",
    "print(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10\n",
    "\n",
    "from names_dataset import NameDataset\n",
    "\n",
    "first_name = 'Gabriel'\n",
    "last_name = 'Marques'\n",
    "print(first_name, last_name)\n",
    "\n",
    "nd = NameDataset()\n",
    "result = nd.search(first_name)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
